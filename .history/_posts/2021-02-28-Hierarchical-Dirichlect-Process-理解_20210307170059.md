---
layout: post
title:  "Hierarchical Dirichlect Process 理解"
author: champion
categories: [ NLP, Nonparametric Bayesian]
image: assets/images/HDP理解.jpg
tags: [featured]
---

最近在看Hierarchical Dirichlect Process(Yee Whye TEH,Michael I. JORDAN)這篇論文，第一次接觸這樣的主題，整理了一下我自己的心得~~~

為什麼要用Hierarchical Dirichlet Process?

舉例來說，在信息檢索領域中，常常我們需要去將不同的文章去分主題，比如說今天有一篇文章"林書豪和周杰倫出新歌"，那這篇文章可能的主題是"運動"和"音樂"，這時候我們可以用DPMM去將這一個文章分成這些主題，但如果今天又有另一篇文章"王建民回國擔任投手，為國爭光"，這篇文章可能的主題是"運動"和"國家"，那又只能用另一個DPMM模型去分類，此時出現一個問題，這兩篇都有一個共同主題"運動"，但是不同的DPMM模型分類為運動，可能用不同的標籤做代表，就會出現同一標籤出現不同主題的情況，無法做到資訊共享，不然就需要將這兩篇文章合併成一篇文章，再使用DPMM去做分類。

那我會先從DP開始，然後再說明HDP

## 一.DP介紹:

DP是一個隨機過程，是由很多個Dirichlet分布所組成，首先先簡單描述一下Dirichlet分布是什麼?

假設今天我們擲一個正反兩面的不公平硬幣(Bernouli分布)，要如何算擲硬幣後正面的機率為多少?

我們會先假設先驗機率來自Beta分布，然後透過擲硬幣後得到的資料推算出後驗機率，因為共軛性(Conjugate)，後驗機率也會是Beta分布，當今天擲很多種不同硬幣時就會變成Bernouli Process。

同樣的情況推廣至多維時，變成擲一個骰子(Mutinomial分布)，此時我們的先驗機率會變成Dirchlet分布，一次模擬骰子每個面的機率，也就是Beta分布的推廣，同樣的先驗機率和後驗機率也具有共軛性(Conjugate)，後驗機率也會是Dirchlet分布，同樣當今天擲很多種不同骰子時就變成Dirichlet Process。

因此在分類文章主題上，不同主題(骰子)由不同字(骰子的不同面)所組成，為Mutinomial分布，多個主題組成一個文章形成混合分布，我們希望從文章中分類出有什麼樣的主題，這時就需要Dirichlet Process去抽出很多的參數，來看哪些屬於同分布(同參數)。

那為什麼需要使用Dirichlet Process作為我們的先驗分布呢?

因為我們的數據是來自一個混合分布，即n個數據來自k個分布，其中n >= k，因此對於同一分布的觀測值，其分布的參數會是一樣的，但如果先驗是連續分布，那麼抽樣結果不可能出現相同的值，可以由下面的數學公式得知，$\theta_{1}$和$\theta_{2}$是由連續分布所產生，透過變數變換的方式讓 $Y = \theta_{1}-\theta_{2}$ ， 因為連續分布單點並不存在機率，因此可得知$\theta_{1}$等於$\theta_{2}$的機率為零

$$P(\theta_{1}=\theta_{2})=P(\theta_{1}-\theta_{2}=0)=P(Y=0)=0$$

因此我們可以透過DP的特性，來解決這樣的問題，DP有兩個參數$\alpha$和$H$，$H$是一個連續分布，而我們的參數並不希望從連續分布裡抽出來，需要有一點離散，這樣才會抽到不同的值，達到分群的效果，因此我們會透過$\alpha$這個參數去控制離散的程度，當$\alpha$很大時，G會很不離散，當$\alpha$很小時，G會變得很離散

以數學表示如下:

$\theta_i$來自G分布，G分布則是從DP裡抽出來，每次從DP抽都會是一個分布，所以有人會說DP是分布的分布

$$\theta_i \sim G$$
$$G \sim DP(\alpha,H)$$

下圖紅色的長條就是我們從DP抽出來的G分布，可以看到是離散的，藍色是H分布，除此之外還可以看到黃色的長條將G分布分成三等份，這是DP的另外一個特性，DP抽出來的G分布對其任意劃分會是Dirichlet分布，也就是說G分布的邊際分布會是Dirichlet分布，用數學表示如下:

$$(G(a_1),G(a_2),....,G(a_k)) \sim DIR(\alpha H(a_1),\alpha H(a_2),.....,\alpha H(a_k)) <=> G \sim DP(\alpha,H),\text{for all partition}\,\alpha_1,\alpha_2,....,\alpha_k$$

## 二.DP的性質

DP的性質主要可以由三種不同的觀點去說明:

### 1.The Stick-Breaking Construction:

這種方法可以說明從DP抽出來的分布有離散性且機率加總為一，那是如何做的呢?

假設我們今天有一根棍子，棍子的長度為1公分，一開始我們從$Beta(1,\alpha)$中先抽出一個數字($\alpha$是之前提到用來控制DP離散程度的參數)，假設抽到0.2，那我們就將棍子長度0.2的部分折斷當作我們第一個權重$\pi_1$，也就是$1*0.2=0.2$公分，然後再從$Beta(1,\alpha)$中抽出一個數字，假設抽到0.3，那我們就是從剩下的棍子長度為0.8中拿走0.3的部分，當作我們的第二個權重，也就是$0.8*0.3=0.24$公分，然後如此下去，直到棍子被折完為止

示意圖如下:

以數學形式表示如下，\(\pi_k^{'}\)就是我們每次抽出來的值，透過乘以扣掉前面權重的值得到當前權重，而\(\phi_k\)則是該權重在機率分布上的值:

$$\pi_k^{'}|\alpha,H\,\sim beta(1,\alpha)\,,\,\pi_k=\pi_k^{'}\prod_{l=1}^{k-1}(1-\pi_l^{'}),\,\phi_k|\alpha,H\,\sim H$$

因此如果我們以下面的方式定義隨機測度G會服從\(DP(\alpha,H)\)，而\(\delta_{\phi_k}\)中文比較難解釋，原文是說\(\delta_{\phi_k}\) is a probability measure concentrated at \(\phi_k\)，意思是\(\phi_k\)是從連續分布\(H\)裡抽出來的是一個隨機變量，以機率的方式來衡量抽到\(\phi_k\)的機率

